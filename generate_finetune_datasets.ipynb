{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9fd6de0a-8c4a-4a09-8c47-2af452e95cd4",
   "metadata": {},
   "source": [
    "# Query/Context Dataset Generation\n",
    "***\n",
    "\n",
    "This notebook walks students through the process of generating datasets of query/context pairs which can be used for two primary purposes:\n",
    "- Fine-tuning an embedding model\n",
    "- Serve as ground truth for retrieval evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e7a0b9a-0f63-465f-b238-286433923925",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davide/Documents/MooC/Corise/VectorSearch/vectorsearch-applications/impactenv/lib/python3.11/site-packages/llama_index/download/download_utils.py:11: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  import pkg_resources\n",
      "/Users/davide/Documents/MooC/Corise/VectorSearch/vectorsearch-applications/impactenv/lib/python3.11/site-packages/pkg_resources/__init__.py:2871: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(pkg)\n"
     ]
    }
   ],
   "source": [
    "from retrieval_evaluation import QueryContextGenerator\n",
    "from llama_index.finetuning import EmbeddingQAFinetuneDataset\n",
    "from prompt_templates import qa_generation_prompt\n",
    "from preprocessing import FileIO\n",
    "from rich import print\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "env = load_dotenv('.env', override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9c94f26-2b9b-4cb4-9be8-8e8c21d0d785",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate generate with openai_key, model_id default is 'gpt-3.5-turbo-0613'\n",
    "generator = QueryContextGenerator(openai_key=os.environ['OPENAI_API_KEY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c56caf-f0d4-48dc-883f-00955af5ec6f",
   "metadata": {},
   "source": [
    "### Load raw data\n",
    "Load raw data from parquet file.  Raw data should be in the same format as the dataset (corpus) created in [Notebook 1](https://github.com/americanthinker/vectorsearch-applications/blob/main/1-Data_Preprocessing_Week1_COLAB.ipynb). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc3833d7-9f28-439d-893c-f76731a599b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (26448, 12)\n",
      "Memory Usage: 2.42+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26448"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = './impact-thoery-minilmL6-256.parquet'\n",
    "data = FileIO().load_parquet(data_path)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c8787b-3c0c-4999-942f-9f8362eb945b",
   "metadata": {},
   "source": [
    "### Data Length Analysis\n",
    "Conduct an analysis of the length of the content chunks.  Can use either raw words or tokens to assess length.  The main point here is to get a sense of the mean length of content chunks in the data and to set the `total_chars` param in the `clean_validate_data` method with an appropriate value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "656fdd2d-9057-4f6c-a767-a8070cec3cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>26448.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>991.729053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>126.344870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>944.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1005.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1060.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1974.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count  26448.000000\n",
       "mean     991.729053\n",
       "std      126.344870\n",
       "min        4.000000\n",
       "25%      944.000000\n",
       "50%     1005.000000\n",
       "75%     1060.000000\n",
       "max     1974.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#in this example the mean content length is @ 1,000\n",
    "lengths = [len(d['content']) for d in data]\n",
    "df = pd.DataFrame(lengths)\n",
    "df.describe() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202dbfca-0a73-4756-b7e7-58f5ef6f62e0",
   "metadata": {},
   "source": [
    "### Split Data\n",
    "\n",
    "The `train_val_split` function will clean and validate the raw data as a first step and then split into user defined train/val splits.  \n",
    "- Cleaning simply strips the keys from the data that are not needed for the query/content generation process\n",
    "- Validation consists of ensuring that only content chunks of length > `total_chars` are passed to the LLM (this step prevents the LLM from asking questions from sparse context)\n",
    "\n",
    "Users define the number of training samples and validation samples to generate.  Number of questions per content chunk can also be set to more than 1, however a note of caution:\n",
    "- Setting `num_questions_per_chunk` > 1 saves time (and money) by asking more than one question per content chunk, however, the dataset will be less diverse.  There is also the potential for the model to generate lower quality questions if the content chunk isn't large enough or meaningful enough to generate more than one question from the content.\n",
    "- Retrieval evaluation results from fine-tuning an embedding model with 200-300 training samples showed an uptick of 5-10% points.  Upper bound on retrieval improvement as a funtion of training sample size is yet to be determined (have fun pushing the boundaries! ðŸ‘Š)\n",
    "- A validation data set is not required for seeing improvement from fine tuning.  The addition of a validation dataset, however, allows a user to test the results of fine tuning on an unseen dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4380c60-c0e9-4f35-b576-59adb173bec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length Training Data: 10\n",
      "Length Validation Data: 5\n"
     ]
    }
   ],
   "source": [
    "#split data into train/val sets\n",
    "#in this example we are creating a training set of n=10, val set of n=5, and asking the LLM to only ask 1 question per chunk. \n",
    "train, val = generator.train_val_split(data, 10, 5, 1, total_chars=950)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2ac9e4-3f6f-4903-88f7-7c397ddf66c6",
   "metadata": {},
   "source": [
    "### Generate QA pairs\n",
    "\n",
    "To generate query/context pairs we need to pass in our cleaned data splits, a question asking generation prompt, and the number of questions per chunk (needs to be same value passed into the `train_val_split` function.\n",
    "The `qa_generation_prompt` is already preconfigured and supplies the LLM with additional context about the Impact Theory show to ensure high quality questions are asked given the additional context.   \n",
    "Print out the prompt to see what is being asked of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "548ee55b-daa5-4ae3-ae8d-c9d67ac8c859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "Impact Theory episode summary and episode guest are below:\n",
       "\n",
       "---------------------\n",
       "Summary: <span style=\"font-weight: bold\">{</span>summary<span style=\"font-weight: bold\">}</span>\n",
       "---------------------\n",
       "Guest: <span style=\"font-weight: bold\">{</span>guest<span style=\"font-weight: bold\">}</span>\n",
       "---------------------\n",
       "Given the Summary and Guest of the episode as context use the following randomly selected transcript section \\  \n",
       "of the episode and not prior knowledge, generate questions that can be answered by the transcript section: \n",
       "\n",
       "---------------------\n",
       "Transcript: <span style=\"font-weight: bold\">{</span>transcript<span style=\"font-weight: bold\">}</span>\n",
       "---------------------\n",
       "\n",
       "Your task is to create <span style=\"font-weight: bold\">{</span>num_questions_per_chunk<span style=\"font-weight: bold\">}</span> questions that can only be answered given the previous context and\n",
       "transcript details. The question should randomly start with How, Why, or What.   \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "Impact Theory episode summary and episode guest are below:\n",
       "\n",
       "---------------------\n",
       "Summary: \u001b[1m{\u001b[0msummary\u001b[1m}\u001b[0m\n",
       "---------------------\n",
       "Guest: \u001b[1m{\u001b[0mguest\u001b[1m}\u001b[0m\n",
       "---------------------\n",
       "Given the Summary and Guest of the episode as context use the following randomly selected transcript section \\  \n",
       "of the episode and not prior knowledge, generate questions that can be answered by the transcript section: \n",
       "\n",
       "---------------------\n",
       "Transcript: \u001b[1m{\u001b[0mtranscript\u001b[1m}\u001b[0m\n",
       "---------------------\n",
       "\n",
       "Your task is to create \u001b[1m{\u001b[0mnum_questions_per_chunk\u001b[1m}\u001b[0m questions that can only be answered given the previous context and\n",
       "transcript details. The question should randomly start with How, Why, or What.   \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(qa_generation_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb27ebe-15ac-4807-a579-6474dce6d548",
   "metadata": {},
   "source": [
    "The output from this function is a llama_index class `EmbeddingQAFinetuneDataset`, which is a simple wrapper for a series of three dictionaries (`corpus`, `queries`, and `relevant_docs`).  The llama_index class is not absolutely necessary, but it is helpful in making transitions smoother when using the llama_index `SentenceTransformersFinetuneEngine` class for fine-tuning.  It takes roughly 80 seconds to generate 100 query/context pairs so a sample size of 300 takes about 4 minutes (much faster than if you were to do this manually!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72a3fd61-44ea-4642-ba5c-b7acbf800e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:14<00:00,  1.46s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:06<00:00,  1.38s/it]\n"
     ]
    }
   ],
   "source": [
    "training_set = generator.generate_qa_embedding_pairs(train, qa_generation_prompt, 1)\n",
    "val_set = generator.generate_qa_embedding_pairs(val, qa_generation_prompt, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e6130c7-d4b6-4d75-b63e-acc85ffed3f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#EmbeddingQAFinetuneDataset has no len, so check length of queries instead\n",
    "len(training_set.queries), len(val_set.queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7be6432-def2-4dcf-8801-1c56d5f09a86",
   "metadata": {},
   "source": [
    "### Dataset Analysis\n",
    "\n",
    "Always a good idea to check the quality of the pairs generated.  Most pairs will be high quality but some will not be, this is a chance for human intervention to adjust the questions manually to ensure the quality remains high. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cda268d4-93b2-4ed4-9700-6819cb7a9af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_qa_pairs(data: EmbeddingQAFinetuneDataset, print_results: bool=True):\n",
    "    pairs = []\n",
    "    for k, v in data.queries.items():\n",
    "        doc_id = data.relevant_docs[k][0]\n",
    "        context = data.corpus[doc_id]\n",
    "        pairs.append((v, context))\n",
    "    if print_results:\n",
    "        for tup in pairs:\n",
    "            print(f'Question: {tup[0]}\\nContext: {tup[1]}\\n\\n')\n",
    "    return pairs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6141be90-7c11-40f7-b635-c82f80ea394b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Question: How did Colin O'Brady's tears react when he cried in the extreme cold?\n",
       "Context: And I realized, to me, I say the only question that truly matters when facing those kinds of obstacles is \n",
       "how will we respond? I'm literally crying at this moment. When it's minus <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>, what happens when you cry? Your tears\n",
       "freeze to your face. It's a pathetic sight, like all around. But I said to myself, and actually with the guidance \n",
       "of Jenna, who's certainly been, you know, a huge guiding force to me, if I haven't mentioned her enough already, \n",
       "I'll continue to. And she goes, look, how far away are you from the first waypoint? And, you know, on my GPS, I've \n",
       "got these, like, markings on the map. And I, at the time, I'm like, you know, I'm <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.54</span> miles away from the first. \n",
       "There's millions of miles. She's like, okay, so you're half a mile away from the first waypoint. Forget about the \n",
       "thousand mile journey. Forget about Captain Lou that's, like, already beating you in this race. Forget about the \n",
       "media, the press, the students falling all in the classroom. Forget about that.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Question: How did Colin O'Brady's tears react when he cried in the extreme cold?\n",
       "Context: And I realized, to me, I say the only question that truly matters when facing those kinds of obstacles is \n",
       "how will we respond? I'm literally crying at this moment. When it's minus \u001b[1;36m25\u001b[0m, what happens when you cry? Your tears\n",
       "freeze to your face. It's a pathetic sight, like all around. But I said to myself, and actually with the guidance \n",
       "of Jenna, who's certainly been, you know, a huge guiding force to me, if I haven't mentioned her enough already, \n",
       "I'll continue to. And she goes, look, how far away are you from the first waypoint? And, you know, on my GPS, I've \n",
       "got these, like, markings on the map. And I, at the time, I'm like, you know, I'm \u001b[1;36m0.54\u001b[0m miles away from the first. \n",
       "There's millions of miles. She's like, okay, so you're half a mile away from the first waypoint. Forget about the \n",
       "thousand mile journey. Forget about Captain Lou that's, like, already beating you in this race. Forget about the \n",
       "media, the press, the students falling all in the classroom. Forget about that.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Question: How does Jay Samit encourage people to overcome the classic excuse of running out of money in business?\n",
       "Context: You're saying when people, the classic excuse is, oh, I ran out of money. Business was right there, but I \n",
       "ran out of money. The same thing is I've seen it countless times in larger companies where people are like, I have \n",
       "this brilliant idea, but they don't get it like you were saying. When you take the ownership yourself and you put \n",
       "yourself in the driver's seat, I think you get a step closer to what I think really has made you so great and so \n",
       "successful. It's certainly what turned me on so much about your book, which is basically Ryan Holiday's concept of \n",
       "the obstacle is the way. It's really amazing when you come up with a big, hairy, audacious idea, goal, something. \n",
       "You want to get me motivated. There's only one thing you have to say to me. You can't. That's it. Tom Bilyeu. Thank\n",
       "you to you. I'm like <span style=\"color: #808000; text-decoration-color: #808000\">...</span> It was funny, my editor of my book said, you're very competitive because I never played \n",
       "sports. I'm like, I'm not competitive. I just have to win. I never thought of myself as that.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Question: How does Jay Samit encourage people to overcome the classic excuse of running out of money in business?\n",
       "Context: You're saying when people, the classic excuse is, oh, I ran out of money. Business was right there, but I \n",
       "ran out of money. The same thing is I've seen it countless times in larger companies where people are like, I have \n",
       "this brilliant idea, but they don't get it like you were saying. When you take the ownership yourself and you put \n",
       "yourself in the driver's seat, I think you get a step closer to what I think really has made you so great and so \n",
       "successful. It's certainly what turned me on so much about your book, which is basically Ryan Holiday's concept of \n",
       "the obstacle is the way. It's really amazing when you come up with a big, hairy, audacious idea, goal, something. \n",
       "You want to get me motivated. There's only one thing you have to say to me. You can't. That's it. Tom Bilyeu. Thank\n",
       "you to you. I'm like \u001b[33m...\u001b[0m It was funny, my editor of my book said, you're very competitive because I never played \n",
       "sports. I'm like, I'm not competitive. I just have to win. I never thought of myself as that.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Question: How does Sam Harris define everyday truth and what factors does he believe influence it?\n",
       "Context: Like even that I think is a task, but let's say that we all agree that we're only going to say what's \n",
       "true. Now this gets really complicated. And I will put forth that what I think is quote unquote true is based on \n",
       "perspective, interpretation and reinforcement. So there's physics, which we don't even understand fully. And then \n",
       "there's everything else. And because a gigantic part of everyday truth, and I don't know if that will help us get \n",
       "to a sort of in the weeds working definition, but everyday truth seems to be predicated on that. You have to take \n",
       "into account the person's perspective. So how do they see the world? Blue, red, right? You have to take into \n",
       "account their interpretation. So looking at data, some people are going to say, no, it doesn't show that. It shows \n",
       "this. And you can get people that look at the data and just violently disagree on what it shows. And then you've \n",
       "got the reinforcement. So if they put out a tweet saying their version of the truth and they get a wall of \n",
       "reinforcement, then they're just one that feels good.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Question: How does Sam Harris define everyday truth and what factors does he believe influence it?\n",
       "Context: Like even that I think is a task, but let's say that we all agree that we're only going to say what's \n",
       "true. Now this gets really complicated. And I will put forth that what I think is quote unquote true is based on \n",
       "perspective, interpretation and reinforcement. So there's physics, which we don't even understand fully. And then \n",
       "there's everything else. And because a gigantic part of everyday truth, and I don't know if that will help us get \n",
       "to a sort of in the weeds working definition, but everyday truth seems to be predicated on that. You have to take \n",
       "into account the person's perspective. So how do they see the world? Blue, red, right? You have to take into \n",
       "account their interpretation. So looking at data, some people are going to say, no, it doesn't show that. It shows \n",
       "this. And you can get people that look at the data and just violently disagree on what it shows. And then you've \n",
       "got the reinforcement. So if they put out a tweet saying their version of the truth and they get a wall of \n",
       "reinforcement, then they're just one that feels good.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Question: How does David Goggins describe the concept of the governor and its impact on human capability?\n",
       "Context: I had to armor plate my mind and It's about what you're saying to yourself, but it also comes at work So \n",
       "whenever I was getting beat down physically mentally spiritually whenever I was going through just saying, you know\n",
       "I would put you know, you can't hurt me can't hurt me just became a message. I you know, I would say to myself and \n",
       "That's just kind of where it comes from What I find so interesting is your concept of the governor that basically \n",
       "I've the chills that an expert is somebody who's gonna tell you What your limits are rather than the person that's \n",
       "out there practicing getting you beyond the limit So what is the governor and how do we strip it out of our lives? \n",
       "I believe that most human beings are only living at about <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40</span>% of their capability so The mind has a governor like a\n",
       "car if you're driving a car and the car has a governor on it The car may say <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">130</span> miles an hour, but the governor \n",
       "set for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">91</span> Once that governor sets in you get to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">91</span> that car starts doing this the car wants to go The car wants to\n",
       "go but that fucking factory said, uh-uh.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Question: How does David Goggins describe the concept of the governor and its impact on human capability?\n",
       "Context: I had to armor plate my mind and It's about what you're saying to yourself, but it also comes at work So \n",
       "whenever I was getting beat down physically mentally spiritually whenever I was going through just saying, you know\n",
       "I would put you know, you can't hurt me can't hurt me just became a message. I you know, I would say to myself and \n",
       "That's just kind of where it comes from What I find so interesting is your concept of the governor that basically \n",
       "I've the chills that an expert is somebody who's gonna tell you What your limits are rather than the person that's \n",
       "out there practicing getting you beyond the limit So what is the governor and how do we strip it out of our lives? \n",
       "I believe that most human beings are only living at about \u001b[1;36m40\u001b[0m% of their capability so The mind has a governor like a\n",
       "car if you're driving a car and the car has a governor on it The car may say \u001b[1;36m130\u001b[0m miles an hour, but the governor \n",
       "set for \u001b[1;36m91\u001b[0m Once that governor sets in you get to \u001b[1;36m91\u001b[0m that car starts doing this the car wants to go The car wants to\n",
       "go but that fucking factory said, uh-uh.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Question: How does Chip Conley describe curiosity as an elixir for life and a key to fostering creativity?\n",
       "Context: I had to move from this place of trying to win, and my definition of success was chips wins to being in a \n",
       "place of like, I think I'm learning. And I was. And if you can be learning in your mid-50s a bunch of things you \n",
       "didn't know before, you're living. And that curiosity becomes sort of an elixir for life. It's like a \n",
       "life-affirming spirit inside of you. How do you get people to do, to foster their creativity, to push it? I'm sure \n",
       "people come up to you and ask like, okay, if creativity is that core thing that's going to make my wrinkles \n",
       "disappear, how do I get more of it? Well, it's curiosity. Curiosity is the elixir for creativity. So creativity and\n",
       "innovation is what we tend to focus on. But I think behind creativity and innovation is this idea of curiosity. \n",
       "What's behind curiosity is a lack of fear to ask naive questions. A four-year-old doesn't edit themselves when they\n",
       "say, why is the sky blue? Four-year-olds ask a lot of questions.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Question: How does Chip Conley describe curiosity as an elixir for life and a key to fostering creativity?\n",
       "Context: I had to move from this place of trying to win, and my definition of success was chips wins to being in a \n",
       "place of like, I think I'm learning. And I was. And if you can be learning in your mid-50s a bunch of things you \n",
       "didn't know before, you're living. And that curiosity becomes sort of an elixir for life. It's like a \n",
       "life-affirming spirit inside of you. How do you get people to do, to foster their creativity, to push it? I'm sure \n",
       "people come up to you and ask like, okay, if creativity is that core thing that's going to make my wrinkles \n",
       "disappear, how do I get more of it? Well, it's curiosity. Curiosity is the elixir for creativity. So creativity and\n",
       "innovation is what we tend to focus on. But I think behind creativity and innovation is this idea of curiosity. \n",
       "What's behind curiosity is a lack of fear to ask naive questions. A four-year-old doesn't edit themselves when they\n",
       "say, why is the sky blue? Four-year-olds ask a lot of questions.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pairs = show_qa_pairs(val_set, print_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62170665-3b89-49ef-a266-ab24a86ab43c",
   "metadata": {},
   "source": [
    "### Save to Disk  \n",
    "Save to disk using your own filepaths, below is an example using the length of the sets as part of the filepath."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "192d9bb8-8535-4d1e-9229-f93cffb368e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set.save_json('./data/training_data_10.json')\n",
    "val_set.save_json('./data/validation_data_5.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
